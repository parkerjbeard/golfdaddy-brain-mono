name: Scheduled Tasks

on:
  schedule:
    # Run daily at 2 AM UTC
    - cron: '0 2 * * *'
  workflow_dispatch:
    inputs:
      task:
        description: 'Task to run'
        required: true
        default: 'all'
        type: choice
        options:
          - all
          - cleanup
          - reports
          - backups
          - health-check

jobs:
  cleanup:
    name: Database Cleanup
    runs-on: ubuntu-latest
    if: github.event_name == 'schedule' || github.event.inputs.task == 'all' || github.event.inputs.task == 'cleanup'
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.11'

      - name: Install dependencies
        working-directory: backend
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt

      - name: Run cleanup tasks
        working-directory: backend
        env:
          DATABASE_URL: ${{ secrets.PRODUCTION_DATABASE_URL }}
        run: |
          python scripts/cleanup_old_data.py
          python scripts/optimize_database.py

  generate-reports:
    name: Generate Reports
    runs-on: ubuntu-latest
    if: github.event_name == 'schedule' || github.event.inputs.task == 'all' || github.event.inputs.task == 'reports'
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.11'

      - name: Install dependencies
        working-directory: backend
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt

      - name: Generate daily reports
        working-directory: backend
        env:
          DATABASE_URL: ${{ secrets.PRODUCTION_DATABASE_URL }}
          SLACK_WEBHOOK_URL: ${{ secrets.SLACK_WEBHOOK_URL }}
        run: |
          python scripts/generate_daily_reports.py
          python scripts/send_analytics_summary.py

  backup:
    name: Database Backup
    runs-on: ubuntu-latest
    if: github.event_name == 'schedule' || github.event.inputs.task == 'all' || github.event.inputs.task == 'backups'
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Install PostgreSQL client
        run: |
          sudo apt-get update
          sudo apt-get install -y postgresql-client

      - name: Backup database
        env:
          DATABASE_URL: ${{ secrets.PRODUCTION_DATABASE_URL }}
          AWS_ACCESS_KEY_ID: ${{ secrets.AWS_ACCESS_KEY_ID }}
          AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          S3_BUCKET: ${{ secrets.BACKUP_S3_BUCKET }}
        run: |
          # Extract database credentials
          export PGPASSWORD=$(echo $DATABASE_URL | sed -n 's/.*:\/\/[^:]*:\([^@]*\)@.*/\1/p')
          export PGHOST=$(echo $DATABASE_URL | sed -n 's/.*@\([^:]*\):.*/\1/p')
          export PGUSER=$(echo $DATABASE_URL | sed -n 's/.*:\/\/\([^:]*\):.*/\1/p')
          export PGDATABASE=$(echo $DATABASE_URL | sed -n 's/.*\/\([^?]*\).*/\1/p')
          
          # Create backup
          BACKUP_FILE="backup-$(date +%Y%m%d-%H%M%S).sql.gz"
          pg_dump | gzip > $BACKUP_FILE
          
          # Upload to S3
          aws s3 cp $BACKUP_FILE s3://$S3_BUCKET/database-backups/

  health-check:
    name: Health Check
    runs-on: ubuntu-latest
    if: github.event.inputs.task == 'health-check'
    
    steps:
      - name: Check API health
        run: |
          response=$(curl -s -o /dev/null -w "%{http_code}" https://api.golfdaddy-brain.com/health)
          if [ $response -eq 200 ]; then
            echo "API is healthy"
          else
            echo "API health check failed with status: $response"
            exit 1
          fi

      - name: Check database connectivity
        working-directory: backend
        env:
          DATABASE_URL: ${{ secrets.PRODUCTION_DATABASE_URL }}
        run: |
          python -c "
          import psycopg2
          from urllib.parse import urlparse
          import os
          
          url = urlparse(os.environ['DATABASE_URL'])
          conn = psycopg2.connect(
              host=url.hostname,
              port=url.port,
              user=url.username,
              password=url.password,
              database=url.path[1:]
          )
          cur = conn.cursor()
          cur.execute('SELECT 1')
          print('Database connection successful')
          "